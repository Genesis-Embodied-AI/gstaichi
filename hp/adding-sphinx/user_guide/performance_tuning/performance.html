
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Performance Tuning &#8212; Taichi 1.8.0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=b51e6972"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'user_guide/performance_tuning/performance';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Profiler" href="profiler.html" />
    <link rel="prev" title="Sparse Matrix" href="../math/sparse_matrix.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="1.8.0" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Taichi 1.8.0 documentation</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    User guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../autoapi/index.html">
    API Reference
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    User guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../autoapi/index.html">
    API Reference
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../get-started/hello_world.html">Hello, World!</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get-started/accelerate_python.html">Accelerate Python with Taichi</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get-started/accelerate_pytorch.html">Accelerate PyTorch with Taichi</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Basic</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../basic/field.html">Fields</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/ndarray.html">Taichi Ndarray</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/layout.html">Fields (advanced)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/offset.html">Coordinate Offsets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/external.html">Interacting with External Arrays</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/sparse.html">Spatially Sparse Data Structures</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Kernels</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../kernels/kernel_function.html">Kernels and Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../kernels/kernel_sync.html">Synchronization between Kernels and Python Scope</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Math</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../math/linear_solver.html">Linear Solver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../math/math_module.html">Math Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../math/sparse_matrix.html">Sparse Matrix</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Performance Tuning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiler.html">Profiler</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../advanced/data_oriented_class.html">Data-Oriented Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dataclass.html">Taichi Dataclass</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/meta.html">Metaprogramming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/quant.html">Use quantized data types</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Differentiable</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../differentiable/differentiable_programming.html">Differentiable Programming</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Type System</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../type_system/type.html">Type System</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../reference/global_settings.html">Global Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/language_reference.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/operator.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/simt.html">SIMT Intrinsics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/syntax_sugars.html">Syntax Sugars</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Internals</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../internals/compilation.html">Life of a Taichi Kernel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internals/internal.html">Internal Designs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">glossary</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../glossary/glossary.html">Glossary</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">FAQs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../faqs/faq.html">Frequently Asked Questions</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">User guide</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Performance Tuning</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="performance-tuning">
<h1>Performance Tuning<a class="headerlink" href="#performance-tuning" title="Link to this heading">#</a></h1>
<section id="for-loop-decorators">
<h2>For-loop decorators<a class="headerlink" href="#for-loop-decorators" title="Link to this heading">#</a></h2>
<p>As discussed in previous topics, Taichi kernels automatically parallelize for-loops in the outermost scope. Our compiler sets the settings automatically to best explore the target architecture. Nonetheless, for Ninjas seeking the final few percent of speed, we give several APIs to allow developers to fine-tune their programs. Specifying a proper <code class="docutils literal notranslate"><span class="pre">block_dim</span></code>, for example, might result in a nearly 3x speed gain in <a class="reference external" href="https://github.com/taichi-dev/taichi/blob/master/python/taichi/examples/mpm3d.py">examples/mpm3d.py</a>.</p>
<p>You can use <code class="docutils literal notranslate"><span class="pre">ti.loop_config</span></code> to set the loop directives for the next for loop. Available directives are:</p>
<ul class="simple">
<li><p><strong>parallelize</strong>: Sets the number of threads to use on CPU</p></li>
<li><p><strong>block_dim</strong>: Sets the number of threads in a block on GPU</p></li>
<li><p><strong>serialize</strong>: If you set <strong>serialize</strong> to <code class="docutils literal notranslate"><span class="pre">True</span></code>, the for loop will run serially, and you can write break statements inside it
(Only applies on range/ndrange fors). Equals to setting <strong>parallelize</strong> to 1.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">break_in_serial_for</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">ti</span><span class="o">.</span><span class="n">i32</span><span class="p">:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">ti</span><span class="o">.</span><span class="n">loop_config</span><span class="p">(</span><span class="n">serialize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>  <span class="c1"># This loop runs serially</span>
        <span class="n">a</span> <span class="o">+=</span> <span class="n">i</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">10</span><span class="p">:</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="n">a</span>

<span class="n">break_in_serial_for</span><span class="p">()</span>  <span class="c1"># returns 55</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">ti</span><span class="o">.</span><span class="n">i32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">fill</span><span class="p">():</span>
    <span class="n">ti</span><span class="o">.</span><span class="n">loop_config</span><span class="p">(</span><span class="n">parallelize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">block_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="c1"># If the kernel is run on the CPU backend, 8 threads will be used to run it</span>
    <span class="c1"># If the kernel is run on the CUDA backend, each block will have 16 threads.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">val</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
</pre></div>
</div>
<section id="background-thread-hierarchy-of-gpus">
<h3>Background: Thread hierarchy of GPUs<a class="headerlink" href="#background-thread-hierarchy-of-gpus" title="Link to this heading">#</a></h3>
<p>It is worthy to quickly discuss the <strong>thread hierarchy</strong> on contemporary GPU architectures in order to help you understand how the previously mentioned for-loop is parallelized.</p>
<p>From fine-grained to coarse-grained, the computation units are as follows: <strong>iteration</strong>, <strong>thread</strong>, <strong>block</strong>, and <strong>grid</strong>.</p>
<ul class="simple">
<li><p><strong>Iteration</strong>: The <strong>body of a for-loop</strong> is an iteration. Each iteration corresponds to a different <code class="docutils literal notranslate"><span class="pre">i</span></code> value in the for-loop.</p></li>
<li><p><strong>Thread</strong>: Iterations are classified as threads. A thread is the smallest parallelized unit. All iterations inside a thread are <strong>serial</strong> in nature. To maximize parallel efficiency, we normally employ one iteration per thread.</p></li>
<li><p><strong>Block</strong>: Threads are organized into groups called blocks. All threads within a block are executed in <strong>parallel</strong> and can share <strong>block local storage</strong>.</p></li>
<li><p><strong>Grid</strong>: Blocks are grouped into grids. A grid is the minimal unit that is <strong>launched</strong> from the host. All blocks within a grid are
executed in <strong>parallel</strong>. In Taichi, each <strong>parallelized for-loop</strong>
is represented as a grid.</p></li>
</ul>
<p>For more details, please see <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#thread-hierarchy">the CUDA C programming
guide</a>.
Note that we employ the CUDA terminology here, other backends such as OpenGL and Metal follow a similar thread hierarchy.</p>
</section>
<section id="example-tuning-the-block-level-parallelism-of-a-for-loop">
<h3>Example: Tuning the block-level parallelism of a for-loop<a class="headerlink" href="#example-tuning-the-block-level-parallelism-of-a-for-loop" title="Link to this heading">#</a></h3>
<p>Programmers may <strong>prepend</strong> some decorator(s) to tweak the property of a
for-loop, e.g.:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">func</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8192</span><span class="p">):</span>  <span class="c1"># no decorator, use default settings</span>
        <span class="o">...</span>

    <span class="n">ti</span><span class="o">.</span><span class="n">loop_config</span><span class="p">(</span><span class="n">block_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>      <span class="c1"># change the property of next for-loop:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8192</span><span class="p">):</span>  <span class="c1"># will be parallelized with block_dim=128</span>
        <span class="o">...</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8192</span><span class="p">):</span>  <span class="c1"># no decorator, use default settings</span>
        <span class="o">...</span>
</pre></div>
</div>
</section>
</section>
<section id="data-layouts">
<h2>Data layouts<a class="headerlink" href="#data-layouts" title="Link to this heading">#</a></h2>
<p>Because Taichi separates data structures from computation, developers may experiment with alternative data layouts. Choosing an efficient layout, like in other programming languages, may significantly enhance performance. Please consult the <a class="reference internal" href="../basic/layout.html"><span class="std std-doc">Fields (advanced)</span></a> section for further information on advanced data layouts in Taichi.</p>
</section>
<section id="local-storage-optimizations">
<h2>Local Storage Optimizations<a class="headerlink" href="#local-storage-optimizations" title="Link to this heading">#</a></h2>
<p>Taichi has a few speed enhancements that take use of <em>fast memory</em> (e.g., CUDA shared memory, L1 cache). Simply, Taichi replaces access to global memory (slow) with access to local memory (quick) wherever feasible, and writes data in local memory (e.g., CUDA shared memory) back to global memory at the conclusion. Such changes keep the original program’s semantics (will be explained later).</p>
<section id="thread-local-storage-tls">
<h3>Thread Local Storage (TLS)<a class="headerlink" href="#thread-local-storage-tls" title="Link to this heading">#</a></h3>
<p>TLS is mostly designed to optimize parallel reduction. When Taichi identifies
a global reduction pattern in a <code class="docutils literal notranslate"><span class="pre">&#64;ti.kernel</span></code>, it automatically applies the TLS
optimizations during code generation, similar to those found in common GPU
reduction implementations.</p>
<p>We will walk through an example using CUDA’s terminology.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">1000000</span><span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">())</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">sum</span><span class="p">():</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
    <span class="n">s</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">+=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

<span class="nb">sum</span><span class="p">()</span>
</pre></div>
</div>
<p>Taichi’s parallel loop is implemented internally with <a class="reference external" href="https://developer.nvidia.com/blog/cuda-pro-tip-write-flexible-kernels-grid-stride-loops/">Grid-Stride Loops</a>.
This means that each physical CUDA thread may handle several items in <code class="docutils literal notranslate"><span class="pre">x</span></code>.
In other words, the number of threads started for <code class="docutils literal notranslate"><span class="pre">sum</span></code> can be less than the shape of <code class="docutils literal notranslate"><span class="pre">x</span></code>.</p>
<p>One optimization offered by this method is the substitution of a <em>thread-local</em> memory access for a global memory access. Instead of directly and atomically adding <code class="docutils literal notranslate"><span class="pre">x[i]</span></code> to the global memory destination <code class="docutils literal notranslate"><span class="pre">s[None]</span></code>, Taichi preallocates a thread-local buffer upon entering the thread, accumulates (<em>non-atomically</em>) the value of <code class="docutils literal notranslate"><span class="pre">x</span></code> into this buffer, and then atomically adds the result of the buffer back to <code class="docutils literal notranslate"><span class="pre">s[None]</span></code> before exiting the thread. If each thread handles <code class="docutils literal notranslate"><span class="pre">N</span></code> items in <code class="docutils literal notranslate"><span class="pre">x</span></code>, the number of atomic additions is reduced to one-Nth of its original amount.</p>
<p>Additionally, the last atomic add to the global memory <code class="docutils literal notranslate"><span class="pre">s[None]</span></code> is optimized using
CUDA’s warp-level intrinsics, further reducing the number of required atomic adds.</p>
<p>Currently, Taichi supports TLS optimization for these reduction operators: <code class="docutils literal notranslate"><span class="pre">add</span></code>,
<code class="docutils literal notranslate"><span class="pre">sub</span></code>, <code class="docutils literal notranslate"><span class="pre">min</span></code> and <code class="docutils literal notranslate"><span class="pre">max</span></code> on <strong>0D</strong> scalar/vector/matrix <code class="docutils literal notranslate"><span class="pre">ti.field</span></code>s. It is not yet
supported on <code class="docutils literal notranslate"><span class="pre">ti.ndarray</span></code>s. <a class="reference external" href="https://github.com/taichi-dev/taichi/pull/2956">Here</a>
is a benchmark comparison when running a global max reduction on a 1-D Taichi field
of 8M floats on an Nvidia GeForce RTX 3090 card:</p>
<ul class="simple">
<li><p>TLS disabled: 5.2 x 1e3 us</p></li>
<li><p>TLS enabled: 5.7 x 1e1 us</p></li>
</ul>
<p>TLS has resulted in a 100x increase in speed. We also demonstrate that TLS reduction sum achieves equivalent performance to CUDA implementations; for more information, see the <a class="reference external" href="https://github.com/taichi-dev/taichi_benchmark/tree/main/reduce_sum">benchmark</a> report.</p>
</section>
<section id="block-local-storage-bls">
<h3>Block Local Storage (BLS)<a class="headerlink" href="#block-local-storage-bls" title="Link to this heading">#</a></h3>
<p>Context: For a sparse field whose last layer is a <code class="docutils literal notranslate"><span class="pre">dense</span></code> SNode (i.e., its layer
hierarchy matches <code class="docutils literal notranslate"><span class="pre">ti.root.(sparse</span> <span class="pre">SNode)+.dense</span></code>), Taichi will assign one CUDA
thread block to each <code class="docutils literal notranslate"><span class="pre">dense</span></code> container (or <code class="docutils literal notranslate"><span class="pre">dense</span></code> block). BLS optimization works
specifically for such kinds of fields.</p>
<p>BLS intends to enhance stencil computing processes by utilizing CUDA shared memory. This optimization begins with users annotating the set of fields they want to cache using <code class="docutils literal notranslate"><span class="pre">ti.block</span> <span class="pre">local</span></code>. At <em>compile time</em>, Taichi tries to identify the accessing range in relation to the <code class="docutils literal notranslate"><span class="pre">dense</span></code> block of these annotated fields. If Taichi is successful, it creates code that first loads all of the accessible data in range into a <em>block local</em> buffer (CUDA’s shared memory), then replaces all accesses to the relevant slots into this buffer.</p>
<p>Here is an example illustrating the usage of BLS. <code class="docutils literal notranslate"><span class="pre">a</span></code> is a sparse field with a
block size of <code class="docutils literal notranslate"><span class="pre">4x4</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">)</span>
<span class="c1"># `a` has a block size of 4x4</span>
<span class="n">ti</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">pointer</span><span class="p">(</span><span class="n">ti</span><span class="o">.</span><span class="n">ij</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">ti</span><span class="o">.</span><span class="n">ij</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">place</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">foo</span><span class="p">():</span>
  <span class="c1"># Taichi will cache `a` into the CUDA shared memory</span>
  <span class="n">ti</span><span class="o">.</span><span class="n">block_local</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">a</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">+</span> <span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
<p>Each loop iteration accesses items with an offset <code class="docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">0]</span></code> and <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">2]</span></code> to its
coordinates, respectively. Therefore, for an entire block spanning from <code class="docutils literal notranslate"><span class="pre">[M,</span> <span class="pre">N]</span></code>
(inclusive) to <code class="docutils literal notranslate"><span class="pre">[M</span> <span class="pre">+</span> <span class="pre">4,</span> <span class="pre">N</span> <span class="pre">+</span> <span class="pre">4]</span></code> (exclusive), the accessed range w.r.t this block
is <code class="docutils literal notranslate"><span class="pre">[M</span> <span class="pre">-</span> <span class="pre">1,</span> <span class="pre">M</span> <span class="pre">+</span> <span class="pre">4)</span> <span class="pre">x</span> <span class="pre">[N,</span> <span class="pre">N</span> <span class="pre">+</span> <span class="pre">6)</span></code> (derived from <code class="docutils literal notranslate"><span class="pre">[M</span> <span class="pre">+</span> <span class="pre">(-1),</span> <span class="pre">M</span> <span class="pre">+</span> <span class="pre">4)</span> <span class="pre">x</span> <span class="pre">[N,</span> <span class="pre">N</span> <span class="pre">+</span> <span class="pre">4</span> <span class="pre">+</span> <span class="pre">2)</span></code>).
The mapping between the global coordinates <code class="docutils literal notranslate"><span class="pre">i,</span> <span class="pre">j</span></code> and the local indices into the
buffer is shown below:</p>
<p><img alt="" src="../../_images/bls_indices_mapping.png" /></p>
<p>You do not need to be concerned about these fundamental elements as a user.
Taichi automatically does all inference and global/block-local mapping.
That is, Taichi will preallocate a CUDA shared memory buffer of size <code class="docutils literal notranslate"><span class="pre">5x6</span></code>, preload <code class="docutils literal notranslate"><span class="pre">a</span></code>’s contents into this buffer, then replace all <code class="docutils literal notranslate"><span class="pre">a</span></code> (global memory) accesses with the buffer in the loop body. While this basic example does not change <code class="docutils literal notranslate"><span class="pre">a</span></code> itself, if a block-cached field is written, Taichi produces code that returns the buffer to global memory.</p>
<div class="note docutils">
<p>BLS does not come cheap. Remember that BLS is intended for stencil computations with a high number of overlapping global memory accesses. If this is not the case, pre-loading and post-storing may actually degrade performance.</p>
<p>Furthermore, recent generations of Nvidia GPU cards have closed the read-only access gap between global memory and shared memory. Currently, we discovered that BLS is more effective for storing the destinations of atomic actions.</p>
<p>As a general rule of thumb, we recommend running benchmarks to determine whether or not you should enable BLS.</p>
</div>
</section>
</section>
<section id="offline-cache">
<h2>Offline Cache<a class="headerlink" href="#offline-cache" title="Link to this heading">#</a></h2>
<p>The first time a Taichi kernel is called, it is implicitly compiled. To decrease the cost in subsequent function calls, the compilation results are retained in an <em>online</em> in-memory cache. The kernel can be loaded and launched immediately as long as it remains unaltered. When the application exits, the cache is no longer accessible. When you restart the programme, Taichi must recompile all kernel routines and rebuild the <em>online</em> in-memory cache. Because of the compilation overhead, the first launch of a Taichi function can typically be slow.</p>
<p>We address this problem by introducing the <em>offline</em> cache feature, which dumps and saves the compilation cache on disk for future runs. The first launch overhead can be drastically reduced in repeated runs. Taichi now constructs and maintains an offline cache by default, as well as providing several options in <code class="docutils literal notranslate"><span class="pre">ti.init()</span></code> for configuring the offline cache behavior.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">offline_cache:</span> <span class="pre">bool</span></code>: Enables or disables offline cache. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">offline_cache_file_path:</span> <span class="pre">str</span></code>: Directory holding the offline cached files. Default: <code class="docutils literal notranslate"><span class="pre">'C:\taichi_cache\ticache\'</span></code> on Windows and <code class="docutils literal notranslate"><span class="pre">'~/.cache/taichi/ticache/'</span></code> on unix-like systems. Directories are automatically populated.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">offline_cache_max_size_of_files:</span> <span class="pre">int32</span></code>: Maximum size of the cached files in Bytes. Default: 100MB. A cleaning process is triggered when the size of the cached files exceeds this limit.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">offline_cache_cleaning_policy:</span> <span class="pre">str</span></code>: Policy about how to replace outdated files in the cache. Options: <code class="docutils literal notranslate"><span class="pre">'never'</span></code>, <code class="docutils literal notranslate"><span class="pre">'version'</span></code>, <code class="docutils literal notranslate"><span class="pre">'lru'</span></code> and <code class="docutils literal notranslate"><span class="pre">'fifo'</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'lru'</span></code>.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">'never'</span></code>: Never cleans and keeps all the cached files regardless of the <code class="docutils literal notranslate"><span class="pre">offline_cache_max_size_of_files</span></code> configuration;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'version'</span></code>: Discards only the old-version cached files with respect to the kernel function;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'lru'</span></code>: Discards the cached files least used recently;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'fifo'</span></code>: Discards the cached files added in the earliest.</p></li>
</ul>
</li>
</ul>
<p>To verify the effect, run some examples twice and observe the launch overhead:
<img alt="" src="../../_images/effect_of_offline_cache.png" /></p>
<div class="note docutils">
<p>If your code behaves abnormally, disable offline cache by setting the environment variable <code class="docutils literal notranslate"><span class="pre">TI_OFFLINE_CACHE=0</span></code> or <code class="docutils literal notranslate"><span class="pre">offline_cache=False</span></code> in the <code class="docutils literal notranslate"><span class="pre">ti.init()</span></code> method call and file an issue with us on <a class="reference external" href="https://github.com/taichi-dev/taichi/issues/new/choose">Taichi’s GitHub repo</a>.</p>
</div>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../math/sparse_matrix.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Sparse Matrix</p>
      </div>
    </a>
    <a class="right-next"
       href="profiler.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Profiler</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#for-loop-decorators">For-loop decorators</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#background-thread-hierarchy-of-gpus">Background: Thread hierarchy of GPUs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-tuning-the-block-level-parallelism-of-a-for-loop">Example: Tuning the block-level parallelism of a for-loop</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-layouts">Data layouts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#local-storage-optimizations">Local Storage Optimizations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#thread-local-storage-tls">Thread Local Storage (TLS)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#block-local-storage-bls">Block Local Storage (BLS)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#offline-cache">Offline Cache</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/user_guide/performance_tuning/performance.md.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2023 Taichi Graphics Inc; 2025 Genesis AI Inc.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>