
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Interacting with External Arrays &#8212; Taichi 1.8.0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=b51e6972"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'user_guide/basic/external';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Spatially Sparse Data Structures" href="sparse.html" />
    <link rel="prev" title="Coordinate Offsets" href="offset.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="1.8.0" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Taichi 1.8.0 documentation</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    User guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../autoapi/index.html">
    API Reference
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    User guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../autoapi/index.html">
    API Reference
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../get-started/hello_world.html">Hello, World!</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get-started/accelerate_python.html">Accelerate Python with Taichi</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get-started/accelerate_pytorch.html">Accelerate PyTorch with Taichi</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Basic</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="field.html">Fields</a></li>
<li class="toctree-l1"><a class="reference internal" href="ndarray.html">Taichi Ndarray</a></li>
<li class="toctree-l1"><a class="reference internal" href="layout.html">Fields (advanced)</a></li>
<li class="toctree-l1"><a class="reference internal" href="offset.html">Coordinate Offsets</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Interacting with External Arrays</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">Spatially Sparse Data Structures</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Kernels</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../kernels/kernel_function.html">Kernels and Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../kernels/kernel_sync.html">Synchronization between Kernels and Python Scope</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Math</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../math/linear_solver.html">Linear Solver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../math/math_module.html">Math Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../math/sparse_matrix.html">Sparse Matrix</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Performance Tuning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../performance_tuning/performance.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance_tuning/profiler.html">Profiler</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../advanced/data_oriented_class.html">Data-Oriented Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dataclass.html">Taichi Dataclass</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/meta.html">Metaprogramming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/quant.html">Use quantized data types</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Differentiable</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../differentiable/differentiable_programming.html">Differentiable Programming</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Type System</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../type_system/type.html">Type System</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../reference/global_settings.html">Global Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/language_reference.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/operator.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/simt.html">SIMT Intrinsics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/syntax_sugars.html">Syntax Sugars</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Internals</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../internals/compilation.html">Life of a Taichi Kernel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internals/internal.html">Internal Designs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">glossary</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../glossary/glossary.html">Glossary</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">FAQs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../faqs/faq.html">Frequently Asked Questions</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">User guide</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Interacting with External Arrays</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="interacting-with-external-arrays">
<h1>Interacting with External Arrays<a class="headerlink" href="#interacting-with-external-arrays" title="Link to this heading">#</a></h1>
<p>This document provides instructions on how to transfer data from external arrays to the Taichi scope and vice versa. For now, the external arrays supported by Taichi are NumPy arrays, PyTorch tensors, and Paddle tensors.</p>
<p>We use NumPy arrays as an example to illustrate the data transfer process because NumPy arrays are the most commonly used external arrays in Taichi. The same steps apply to PyTorch tensors and Paddle tensors.</p>
<p>There are two ways to import a NumPy array <code class="docutils literal notranslate"><span class="pre">arr</span></code> to the Taichi scope:</p>
<ul class="simple">
<li><p>Create a Taichi field <code class="docutils literal notranslate"><span class="pre">f</span></code>, whose shape and dtype match the shape and dtype of <code class="docutils literal notranslate"><span class="pre">arr</span></code>, and call <code class="docutils literal notranslate"><span class="pre">f.from_numpy(arr)</span></code> to copy the data in <code class="docutils literal notranslate"><span class="pre">arr</span></code> into <code class="docutils literal notranslate"><span class="pre">f</span></code>. This approach is preferred when the original array is visited frequently from elsewhere in the Taichi scope (for example, in texture sampling).</p></li>
<li><p>Pass <code class="docutils literal notranslate"><span class="pre">arr</span></code> as an argument to a kernel or a Taichi function using <code class="docutils literal notranslate"><span class="pre">ti.types.ndarray()</span></code> as type hint. The argument is passed by reference without creating a copy of <code class="docutils literal notranslate"><span class="pre">arr</span></code>. Thus, any modification to this argument from inside a kernel or Taichi function also changes the original array <code class="docutils literal notranslate"><span class="pre">arr</span></code>. This approach is preferred when the kernel or Taichi function that takes in the argument needs to process the original array (for storage or filtering, for example).</p></li>
</ul>
<div class="note docutils">
<p><code class="docutils literal notranslate"><span class="pre">from_numpy()</span> <span class="pre">/</span> <span class="pre">from_torch()</span></code> can take in any numpy array or torch Tensor, no matter it’s contiguous or not. Taichi will manage its own copy of data. However, when passing an argument to a Taichi kernel, only contiguous numpy arrays or torch Tensors are supported.</p>
</div>
<section id="data-transfer-between-numpy-arrays-and-taichi-fields">
<h2>Data transfer between NumPy arrays and Taichi fields<a class="headerlink" href="#data-transfer-between-numpy-arrays-and-taichi-fields" title="Link to this heading">#</a></h2>
<p>To import data from a NumPy array to a Taichi field, first make sure that the field and the array have the same shape:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">9</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">x</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="c1">#[[0 1 2]</span>
<span class="c1"># [3 4 5]</span>
<span class="c1"># [6 7 8]]</span>
</pre></div>
</div>
<p>In the example above, the scalar field <code class="docutils literal notranslate"><span class="pre">x</span></code> and the array <code class="docutils literal notranslate"><span class="pre">a</span></code> have the same shape <code class="docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">3)</span></code>. This operation would fail if their shapes did not match. Shape matching of a vector or matrix field with a NumPy array is slightly different, which will be discussed in a later section.</p>
<p>The field should also have the same dtype as the array; otherwise, an implicit type casting would occur - see <a class="reference internal" href="../type_system/type.html"><span class="std std-doc">type system</span></a>.</p>
<p>Conversely, to export the data in <code class="docutils literal notranslate"><span class="pre">x</span></code> to a NumPy array, call <code class="docutils literal notranslate"><span class="pre">to_numpy()</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">arr</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="c1">#array([[0, 1, 2],</span>
<span class="c1">#       [3, 4, 5],</span>
<span class="c1">#       [6, 7, 8]], dtype=int32)</span>
</pre></div>
</div>
</section>
<section id="data-transfer-between-pytorch-paddle-tensors-and-taichi-fields">
<h2>Data transfer between PyTorch/Paddle tensors and Taichi fields<a class="headerlink" href="#data-transfer-between-pytorch-paddle-tensors-and-taichi-fields" title="Link to this heading">#</a></h2>
<p>Data transfer between a PyTorch tensor and a Taichi field is similar to the NumPy case above: Call <code class="docutils literal notranslate"><span class="pre">from_torch()</span></code> for data import and <code class="docutils literal notranslate"><span class="pre">to_torch()</span></code> for data export. But note that <code class="docutils literal notranslate"><span class="pre">to_torch()</span></code> requires one more argument <code class="docutils literal notranslate"><span class="pre">device</span></code>, which specifies the PyTorch device:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tensor</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to_torch</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1"># device(type=&#39;cuda&#39;, index=0)</span>
</pre></div>
</div>
<p>For Paddle, you need to specify the device by calling <code class="docutils literal notranslate"><span class="pre">paddle.CPUPlace()</span></code> or <code class="docutils literal notranslate"><span class="pre">paddle.CUDAPlace(n)</span></code>, where <code class="docutils literal notranslate"><span class="pre">n</span></code> is an optional ID set to 0 by default.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">CPUPlace</span><span class="p">()</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to_paddle</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="external-array-shapes">
<h2>External array shapes<a class="headerlink" href="#external-array-shapes" title="Link to this heading">#</a></h2>
<p>When transferring data between a <code class="docutils literal notranslate"><span class="pre">ti.field/ti.Vector.field/ti.Matrix.field</span></code> and a NumPy array, you need to make sure that the shapes of both sides are aligned. The shape matching rules are summarized as below:</p>
<ol class="arabic">
<li><p>When importing data to or exporting data from a scalar field, ensure that <strong>the shape of the corresponding NumPy array, PyTorch tensor, or Paddle tensor equals the shape of the scalar field</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">field</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
<span class="n">field</span><span class="o">.</span><span class="n">shape</span>  <span class="c1"># (256, 512)</span>

<span class="n">array</span> <span class="o">=</span> <span class="n">field</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">array</span><span class="o">.</span><span class="n">shape</span>  <span class="c1"># (256, 512)</span>

<span class="n">field</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>  <span class="c1"># the input array must be of shape (256, 512)</span>
</pre></div>
</div>
<p>An illustration is shown below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>                               field.shape[1]=array.shape[1]
                                           (=512)
                                  ┌───────────────────────┐

                               ┌  ┌───┬───┬───┬───┬───┬───┐  ┐
                               │  │   │   │   │   │   │   │  │
                               │  ├───┼───┼───┼───┼───┼───┤  │
field.shape[0]=array.shape[0]  │  │   │   │   │   │   │   │  │
         (=256)                │  ├───┼───┼───┼───┼───┼───┤  │
                               │  │   │   │   │   │   │   │  │
                               └  └───┴───┴───┴───┴───┴───┘  ┘
</pre></div>
</div>
</li>
<li><p>When importing data to or exporting data from an <code class="docutils literal notranslate"><span class="pre">n</span></code>-dimensional vector field, ensure that <strong>the shape of the corresponding NumPy array, PyTorch tensor, or Paddle tensor is set to</strong> <code class="docutils literal notranslate"><span class="pre">(*field_shape,</span> <span class="pre">n)</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">field</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">Vector</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
<span class="n">field</span><span class="o">.</span><span class="n">shape</span>  <span class="c1"># (256, 512)</span>
<span class="n">field</span><span class="o">.</span><span class="n">n</span>      <span class="c1"># 3</span>

<span class="n">array</span> <span class="o">=</span> <span class="n">field</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">array</span><span class="o">.</span><span class="n">shape</span>  <span class="c1"># (256, 512, 3)</span>

<span class="n">field</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>  <span class="c1"># the input array must in the shape (256, 512, 3)</span>
</pre></div>
</div>
<p>An illustration is shown below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>                                 field.shape[1]=array.shape[1]
                                            (=512)
                                 ┌─────────────────────────────┐

                              ┌  ┌─────────┬─────────┬─────────┐  ┐
                              │  │[*, *, *]│[*, *, *]│[*, *, *]│  │
                              │  ├─────────┼─────────┼─────────┤  │
field.shape[0]=array.shape[0] │  │[*, *, *]│[*, *, *]│[*, *, *]│  │        [*, *, *]
         (=256)               │  ├─────────┼─────────┼─────────┤  │        └───────┘
                              │  │[*, *, *]│[*, *, *]│[*, *, *]│  │   n=array.shape[2]=3
                              └  └─────────┴─────────┴─────────┘  ┘
</pre></div>
</div>
</li>
<li><p>When importing data to or exporting data from an <code class="docutils literal notranslate"><span class="pre">n</span></code>-by-<code class="docutils literal notranslate"><span class="pre">m</span></code> (<code class="docutils literal notranslate"><span class="pre">n</span> <span class="pre">x</span> <span class="pre">m</span></code>) matrix field,  ensure that <strong>the shape of the corresponding NumPy array, PyTorch tensor, or Paddle tensor is set to</strong> <code class="docutils literal notranslate"><span class="pre">(*field_shape,</span> <span class="pre">n,</span> <span class="pre">m)</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">field</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">Matrix</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">ti</span><span class="o">.</span><span class="n">i32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
<span class="n">field</span><span class="o">.</span><span class="n">shape</span>  <span class="c1"># (256, 512)</span>
<span class="n">field</span><span class="o">.</span><span class="n">n</span>      <span class="c1"># 3</span>
<span class="n">field</span><span class="o">.</span><span class="n">m</span>      <span class="c1"># 4</span>

<span class="n">array</span> <span class="o">=</span> <span class="n">field</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">array</span><span class="o">.</span><span class="n">shape</span>  <span class="c1"># (256, 512, 3, 4)</span>

<span class="n">field</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>  <span class="c1"># the input array must be of shape (256, 512, 3, 4)</span>
</pre></div>
</div>
</li>
<li><p>When importing data to a struct field, export the data of the corresponding external array as <strong>a dictionary of NumPy arrays, PyTorch tensors, or Paddle tensors</strong> with keys being struct member names and values being struct member arrays. Nested structs are exported as nested dictionaries:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">field</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">Struct</span><span class="o">.</span><span class="n">field</span><span class="p">({</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">i32</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">vector</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="nb">float</span><span class="p">)},</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
<span class="n">field</span><span class="o">.</span><span class="n">shape</span> <span class="c1"># (256, 512)</span>

<span class="n">array_dict</span> <span class="o">=</span> <span class="n">field</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">array_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="c1"># dict_keys([&#39;a&#39;, &#39;b&#39;])</span>
<span class="n">array_dict</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span> <span class="c1"># (256, 512)</span>
<span class="n">array_dict</span><span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span> <span class="c1"># (256, 512, 3)</span>

<span class="n">field</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">array_dict</span><span class="p">)</span> <span class="c1"># the input array must have the same keys as the field</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="using-external-arrays-as-taichi-kernel-arguments">
<h2>Using external arrays as Taichi kernel arguments<a class="headerlink" href="#using-external-arrays-as-taichi-kernel-arguments" title="Link to this heading">#</a></h2>
<p>Use type hint <code class="docutils literal notranslate"><span class="pre">ti.types.ndarray()</span></code> to pass external arrays as kernel arguments.</p>
<section id="an-entry-level-example">
<h3>An entry-level example<a class="headerlink" href="#an-entry-level-example" title="Link to this heading">#</a></h3>
<p>The following example shows the most basic way to call <code class="docutils literal notranslate"><span class="pre">ti.types.ndarray()</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">taichi</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ti</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">ti</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">ndarray</span><span class="p">()):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>  <span class="c1"># a parallel for loop</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="n">j</span>

<span class="n">test</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="advanced-usage">
<h3>Advanced usage<a class="headerlink" href="#advanced-usage" title="Link to this heading">#</a></h3>
<p>Assume that <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> are both 2D arrays of the same shape and dtype. For each cell <code class="docutils literal notranslate"><span class="pre">(i,</span> <span class="pre">j)</span></code> in <code class="docutils literal notranslate"><span class="pre">a</span></code>, we want to calculate the difference between its value and the average of its four neighboring cells while storing the result in the corresponding cell in <code class="docutils literal notranslate"><span class="pre">b</span></code>. In this case, cells on the boundary, which are cells with fewer than four neighbors, are ruled out for simplicity. This operation is usually denoted as the <em>Discrete Laplace Operator</em>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="mi">4</span>
</pre></div>
</div>
<p>Such an operation is typically very slow, even with NumPy’s vectorization as shown below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span>               <span class="n">a</span><span class="p">[</span> <span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span>
                  <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>                 <span class="o">+</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">:]</span> <span class="o">+</span>
                                 <span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span>  <span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>But Taichi can meet the same purpose in one parallel <code class="docutils literal notranslate"><span class="pre">for</span></code> loop only:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">ndarray</span><span class="p">(),</span> <span class="n">b</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">ndarray</span><span class="p">()):</span>  <span class="c1"># assume a, b have the same shape</span>
    <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">ti</span><span class="o">.</span><span class="n">ndrange</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">):</span>  <span class="c1"># one parallel for loop</span>
        <span class="k">if</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">H</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">W</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="mi">4</span>
</pre></div>
</div>
<p>Not only is this code snippet more readable than the NumPy version above, but it also runs way faster even on the CPU backend.</p>
<div class="note docutils">
<p>The elements in an external array must be indexed using a single square bracket. This contrasts with a Taichi vector field or matrix field where field members and elements are indexed separately:</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">Vector</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">copy_vector</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">template</span><span class="p">(),</span> <span class="n">y</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">ndarray</span><span class="p">()):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">ti</span><span class="o">.</span><span class="n">ndrange</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">ti</span><span class="o">.</span><span class="n">static</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)):</span>
            <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="c1"># correct</span>
            <span class="c1"># y[i][j][k] = x[i, j][k] incorrect</span>
            <span class="c1"># y[i, j][k] = x[i, j][k] incorrect</span>
</pre></div>
</div>
<p>In addition, external arrays in a Taichi kernel are indexed using their <strong>physical memory layout</strong>. For PyTorch users, this means that a PyTorch tensor <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.Tensor.contiguous.html">needs to be made contiguous</a> before being passed into a Taichi kernel:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">T</span> <span class="c1"># Transposing the tensor returns a view of the tensor which is not contiguous</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">copy_scalar</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">template</span><span class="p">(),</span> <span class="n">y</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">ndarray</span><span class="p">()):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
        <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>

<span class="c1"># copy(x, y) # error!</span>
<span class="n">copy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span> <span class="c1"># correct</span>
<span class="n">copy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">contiguous</span><span class="p">())</span> <span class="c1"># correct</span>
</pre></div>
</div>
</section>
</section>
<section id="faq">
<h2>FAQ<a class="headerlink" href="#faq" title="Link to this heading">#</a></h2>
<section id="can-i-use-ti-kernel-to-accelerate-a-numpy-function">
<h3>Can I use <code class="docutils literal notranslate"><span class="pre">&#64;ti.kernel</span></code> to accelerate a NumPy function?<a class="headerlink" href="#can-i-use-ti-kernel-to-accelerate-a-numpy-function" title="Link to this heading">#</a></h3>
<p>Unlike other Python acceleration frameworks, such as Numba, Taichi does not compile NumPy functions. Calling NumPy functions inside the Taichi scope is not supported, as the following example shows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">invalid_sum</span><span class="p">(</span><span class="n">arr</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">ndarray</span><span class="p">()):</span>
    <span class="n">total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>  <span class="c1"># Not supported!</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>If you want to use a NumPy function, which lacks a counterpart in Taichi, you can call the function in the Python scope as usual and pass the processed array to Taichi kernels via <code class="docutils literal notranslate"><span class="pre">ti.types.ndarray()</span></code>. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">233</span><span class="p">)</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>  <span class="c1"># arr is a NumPy ndarray</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">valid_example</span><span class="p">(</span><span class="n">arr</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">ndarray</span><span class="p">(),</span> <span class="n">indices</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">ndarray</span><span class="p">()):</span>
    <span class="n">min_element</span> <span class="o">=</span> <span class="n">arr</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="o">...</span>
</pre></div>
</div>
</section>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="offset.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Coordinate Offsets</p>
      </div>
    </a>
    <a class="right-next"
       href="sparse.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Spatially Sparse Data Structures</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-transfer-between-numpy-arrays-and-taichi-fields">Data transfer between NumPy arrays and Taichi fields</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-transfer-between-pytorch-paddle-tensors-and-taichi-fields">Data transfer between PyTorch/Paddle tensors and Taichi fields</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#external-array-shapes">External array shapes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-external-arrays-as-taichi-kernel-arguments">Using external arrays as Taichi kernel arguments</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#an-entry-level-example">An entry-level example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#advanced-usage">Advanced usage</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#faq">FAQ</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#can-i-use-ti-kernel-to-accelerate-a-numpy-function">Can I use <code class="docutils literal notranslate"><span class="pre">@ti.kernel</span></code> to accelerate a NumPy function?</a></li>
</ul>
</li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/user_guide/basic/external.md.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2023 Taichi Graphics Inc; 2025 Genesis AI Inc.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>