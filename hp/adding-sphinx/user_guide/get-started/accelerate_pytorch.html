
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Accelerate PyTorch with Taichi &#8212; Taichi 1.8.0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=b51e6972"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'user_guide/get-started/accelerate_pytorch';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Fields" href="../basic/field.html" />
    <link rel="prev" title="Accelerate Python with Taichi" href="accelerate_python.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="1.8.0" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Taichi 1.8.0 documentation</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    User guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../autoapi/index.html">
    API Reference
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    User guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../autoapi/index.html">
    API Reference
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="hello_world.html">Hello, World!</a></li>
<li class="toctree-l1"><a class="reference internal" href="accelerate_python.html">Accelerate Python with Taichi</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Accelerate PyTorch with Taichi</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Basic</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../basic/field.html">Fields</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/ndarray.html">Taichi Ndarray</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/layout.html">Fields (advanced)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/offset.html">Coordinate Offsets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/external.html">Interacting with External Arrays</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/sparse.html">Spatially Sparse Data Structures</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Kernels</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../kernels/kernel_function.html">Kernels and Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../kernels/kernel_sync.html">Synchronization between Kernels and Python Scope</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Math</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../math/linear_solver.html">Linear Solver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../math/math_module.html">Math Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../math/sparse_matrix.html">Sparse Matrix</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Performance Tuning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../performance_tuning/performance.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance_tuning/profiler.html">Profiler</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../advanced/data_oriented_class.html">Data-Oriented Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dataclass.html">Taichi Dataclass</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/meta.html">Metaprogramming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/quant.html">Use quantized data types</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Differentiable</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../differentiable/differentiable_programming.html">Differentiable Programming</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Type System</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../type_system/type.html">Type System</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../reference/global_settings.html">Global Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/language_reference.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/operator.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/simt.html">SIMT Intrinsics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/syntax_sugars.html">Syntax Sugars</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Internals</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../internals/compilation.html">Life of a Taichi Kernel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internals/internal.html">Internal Designs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">glossary</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../glossary/glossary.html">Glossary</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">FAQs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../faqs/faq.html">Frequently Asked Questions</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">User guide</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Accelerate PyTorch with Taichi</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="accelerate-pytorch-with-taichi">
<h1>Accelerate PyTorch with Taichi<a class="headerlink" href="#accelerate-pytorch-with-taichi" title="Link to this heading">#</a></h1>
<p>Taichi and Torch serve different application scenarios but can complement each other.</p>
<ul class="simple">
<li><p>Taichi provides finer control over parallelization and enables more ‘granular’ (element-level) operations, giving its users much more flexibilities.</p></li>
<li><p>Torch abstracts such details into Tensor-level operations like LEGO bricks, enabling its users to focus on building ML (Machine Learning) models.</p></li>
</ul>
<p>This document uses two examples to explain how to use Taichi kernel to implement data preprocessing operators and custom high-performance ML operators.</p>
<section id="data-preprocessing">
<h2>Data preprocessing<a class="headerlink" href="#data-preprocessing" title="Link to this heading">#</a></h2>
<p>This section uses padding as an example to show you how Taichi can complement PyTorch in data preprocessing.</p>
<p>Padding is a commonly-used data preprocessing technique in machine learning. For example, padding can prevent convolution operations from changing the size of the input image. However, no PyTorch operators are designed specifically for padding in a specific customized pattern. Previously, you have two options to work around this:</p>
<ul class="simple">
<li><p>Using Python or PyTorch to iterate over matrix elements.</p></li>
<li><p>Writing a C++/CUDA operator and connecting it to PyTorch via Python’s custom operator extension.</p></li>
</ul>
<p>The former has very poor efficiency and could become a drain of the neural network training performance; the latter requires large amount of domain-specific knowledge about the underlying hardware architectures and it could take a long while to get started.</p>
<p>Now, you can use Taichi to pad a brick wall of a specific customized pattern in a much more efficient way.</p>
<p>The following sections compare PyTorch’s implementation of this workflow with Taichi’s implementation:</p>
<ol class="arabic">
<li><p>Create a ‘brick’ and fill it with changing colors.</p>
<p><img alt="brick" src="https://user-images.githubusercontent.com/93570324/191012540-4035cf95-c9e0-4fcf-94f1-1be4cc8abfae.png" /></p>
</li>
<li><p>Repeat the bricks horizontally with a fixed offset to form a staggered layout.</p>
<p><img alt="bricks" src="https://user-images.githubusercontent.com/93570324/191012612-2834db6b-8c31-4986-92a9-0c462b2ee9c5.png" /></p>
</li>
</ol>
<section id="padding-with-pytorch">
<h3>Padding with PyTorch<a class="headerlink" href="#padding-with-pytorch" title="Link to this heading">#</a></h3>
<p>The following code implements a PyTorch kernel <code class="docutils literal notranslate"><span class="pre">torch_pad()</span></code> for padding. To improve efficiency, the kernel turns the padding process into a series of native PyTorch matrix operations. But such matrix operations are usually unintuitive and require so many intermediate results to be stored in the GPU memory that old GPUs with less RAM cannot even afford them.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">torch_pad</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">tile</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="c1"># image_pixel_to_coord</span>
    <span class="n">arr</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_height</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">ph</span> <span class="o">-</span> <span class="n">arr</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">arr</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-=</span> <span class="n">pw</span>
    <span class="n">arr1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">))</span>
    <span class="c1"># map_coord</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">arr1</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">tile_height</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">floor</span><span class="p">((</span><span class="n">arr1</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">v</span> <span class="o">*</span> <span class="n">shift_y</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="n">tile_width</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
    <span class="n">uu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">u</span><span class="p">,</span> <span class="n">u</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">vv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">v</span><span class="p">,</span> <span class="n">v</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">arr2</span> <span class="o">=</span> <span class="n">arr1</span> <span class="o">-</span> <span class="n">uu</span> <span class="o">*</span> <span class="n">shift_x</span> <span class="o">-</span> <span class="n">vv</span> <span class="o">*</span> <span class="n">shift_y</span>
    <span class="c1"># coord_to_tile_pixel</span>
    <span class="n">arr2</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">tile_height</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">arr2</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">table</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">arr2</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">))</span>
    <span class="n">table</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
    <span class="n">inds</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">mv</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">gathered</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">tile</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">inds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">gathered</span>

<span class="k">with</span> <span class="n">Timer</span><span class="p">():</span>
    <span class="n">gathered</span> <span class="o">=</span> <span class="n">torch_pad</span><span class="p">(</span><span class="n">coords</span><span class="p">,</span> <span class="n">tile</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="padding-with-taichi">
<h3>Padding with Taichi<a class="headerlink" href="#padding-with-taichi" title="Link to this heading">#</a></h3>
<p>The following code implements a Taichi kernel <code class="docutils literal notranslate"><span class="pre">ti_pad()</span></code> for padding. The kernel iterates over the pixels in the output image, works out each pixel’s corresponding position in the input ‘brick’, and fills the pixel with the RGB color in that position.</p>
<p>Taichi automatically runs the top-level for-loops in parallel, and matrix operations written in Taichi are much more readable. Moreover, as you can tell from the following code, <code class="docutils literal notranslate"><span class="pre">ti_pad()</span></code> takes in the PyTorch tensors directly so that it can reuse the memory allocated by PyTorch and would not cause extra overhead from the data transfer between the two frameworks.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ti_pad</span><span class="p">(</span><span class="n">image_pixels</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">ndarray</span><span class="p">(),</span> <span class="n">tile</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">ndarray</span><span class="p">()):</span>
    <span class="k">for</span> <span class="n">row</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">ti</span><span class="o">.</span><span class="n">ndrange</span><span class="p">(</span><span class="n">image_height</span><span class="p">,</span> <span class="n">image_width</span><span class="p">):</span>
        <span class="c1"># image_pixel_to_coord</span>
        <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">ivec2</span><span class="p">(</span><span class="n">col</span> <span class="o">-</span> <span class="n">pw</span><span class="p">,</span> <span class="n">image_height</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">row</span> <span class="o">+</span> <span class="n">ph</span><span class="p">)</span>
        <span class="c1"># map_coord</span>
        <span class="n">v</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">i32</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">y1</span> <span class="o">/</span> <span class="n">tile_height</span><span class="p">)</span>
        <span class="n">u</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">i32</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">floor</span><span class="p">((</span><span class="n">x1</span> <span class="o">-</span> <span class="n">v</span> <span class="o">*</span> <span class="n">shift_y</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="n">tile_width</span><span class="p">)</span>
        <span class="n">x2</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">ivec2</span><span class="p">(</span><span class="n">x1</span> <span class="o">-</span> <span class="n">u</span> <span class="o">*</span> <span class="n">shift_x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">v</span> <span class="o">*</span> <span class="n">shift_y</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                 <span class="n">y1</span> <span class="o">-</span> <span class="n">u</span> <span class="o">*</span> <span class="n">shift_x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">v</span> <span class="o">*</span> <span class="n">shift_y</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="c1"># coord_to_tile_pixel</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">ivec2</span><span class="p">(</span><span class="n">tile_height</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y2</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
        <span class="n">image_pixels</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">tile</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
<span class="k">with</span> <span class="n">Timer</span><span class="p">():</span>
    <span class="n">ti_pad</span><span class="p">(</span><span class="n">image_pixels</span><span class="p">,</span> <span class="n">tile</span><span class="err">）</span>
    <span class="n">ti</span><span class="o">.</span><span class="n">sync</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="performance-comparison">
<h3>Performance comparison<a class="headerlink" href="#performance-comparison" title="Link to this heading">#</a></h3>
<p>As the following table shows, the PyTorch kernel takes 30.392 ms[1] to complete padding; the Taichi kernel takes 0.267 ms only. Taichi outruns PyTorch by more than 100x (30.392/0.267).</p>
<p><code class="docutils literal notranslate"><span class="pre">torch_pad()</span></code> launches 58 CUDA kernels, whilst Taichi compiles all computation into one CUDA kernel. The fewer the CUDA kernels, the less GPU launch overhead is incurred. Moreover, the Taichi kernel manages to save a lot more redundant memory operations than the PyTorch kernel. The GPU launch overhead and the redundant memory operations are the potential source for optimization and acceleration.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Kernel function</p></th>
<th class="head text-left"><p>Average time (ms)</p></th>
<th class="head text-left"><p>CUDA kernels launched (number)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">torch_pad()</span></code></p></td>
<td class="text-left"><p>30.392</p></td>
<td class="text-left"><p>58</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">ti_pad()</span></code></p></td>
<td class="text-left"><p>0.267</p></td>
<td class="text-left"><p>1</p></td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<div><ul class="simple">
<li><p>GPU: RTX3090</p></li>
<li><p>PyTorch version: v1.12.1; Taichi version: v1.1.0</p></li>
<li><p>The actual acceleration rate may vary depending on your implementation and GPU setup.</p></li>
</ul>
</div></blockquote>
</section>
</section>
<section id="customize-ml-operators">
<h2>Customize ML operators<a class="headerlink" href="#customize-ml-operators" title="Link to this heading">#</a></h2>
<p>Researchers in machine learning usually spend a lot of time designing model architectures. Because they cannot find decent support for their newly-designed or customized operators from PyTorch, they have to spend time studying CUDA for fine tuning and to improve efficiency. But writing in CUDA is hard, tuning CUDA code is even harder, and accelerating model iteration with CUDA is difficult.</p>
<p><a class="reference external" href="https://github.com/BlinkDL/RWKV-CUDA">This repo</a> introduces an example of customizing an ML operator in CUDA. The author developed an RWKV language model using sort of a one-dimensional depthwise convolution custom operator. The model does not involve much computation but still runs slow because PyTorch does not have native support for it.  So, the author customized the operator in CUDA using a set of optimization techniques, such as loop fusion and Shared Memory, and achieved a performance 20x better than he did with PyTorch.</p>
<p>Referring to the CUDA code<a href="#id8"><span class="problematic" id="id1">[^3]</span></a>, we customized a Taichi depthwise convolution operator<a href="#id9"><span class="problematic" id="id2">[^4]</span></a> in the RWKV model using the same optimization techniques.</p>
<p>The function of the depth wise convolution operator:</p>
<ol class="arabic simple">
<li><p>Iterates over two input Tensors <code class="docutils literal notranslate"><span class="pre">w</span></code> and <code class="docutils literal notranslate"><span class="pre">k</span></code>,</p></li>
<li><p>Adds up the product of the respective elements in <code class="docutils literal notranslate"><span class="pre">w</span></code> and <code class="docutils literal notranslate"><span class="pre">k</span></code> into <code class="docutils literal notranslate"><span class="pre">s</span></code>,</p></li>
<li><p>Saves <code class="docutils literal notranslate"><span class="pre">s</span></code> to an output Tensor <code class="docutils literal notranslate"><span class="pre">out</span></code>.</p></li>
</ol>
<p>The following subsections take the Baseline implementations as an example to show you how to implement a depthwise convolution operator with Python, PyTorch, CUDA, and Taichi, and how they compare to each other. With Taichi, you can accelerate your ML model development with ease and get rid of the tedious low-level parallel programming.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Implementation</p></th>
<th class="head text-left"><p>Readability</p></th>
<th class="head text-left"><p>Performance</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Python</p></td>
<td class="text-left"><p>Excellent</p></td>
<td class="text-left"><p>The slowest</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>PyTorch</p></td>
<td class="text-left"><p>Poor</p></td>
<td class="text-left"><p>Slow</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>CUDA</p></td>
<td class="text-left"><p>Poor</p></td>
<td class="text-left"><p>Fast</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Taichi</p></td>
<td class="text-left"><p>Excellent</p></td>
<td class="text-left"><p>Comparable to that of CUDA or even better</p></td>
</tr>
</tbody>
</table>
</div>
<section id="implement-a-depthwise-convolution-operator-with-python">
<h3>Implement a depthwise convolution operator with Python<a class="headerlink" href="#implement-a-depthwise-convolution-operator-with-python" title="Link to this heading">#</a></h3>
<p>The Python reference code is straightforward and easy to understand, but it runs so slow that the result can hardly make itself into the diagram below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">run_formula_very_slow</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">eps</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">T</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">eps</span>
                <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">t</span><span class="o">-</span><span class="n">T</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
                    <span class="n">s</span> <span class="o">+=</span> <span class="n">w</span><span class="p">[</span><span class="n">c</span><span class="p">][</span><span class="mi">0</span><span class="p">][(</span><span class="n">T</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">-</span><span class="p">(</span><span class="n">t</span><span class="o">-</span><span class="n">u</span><span class="p">)]</span> <span class="o">*</span> <span class="n">k</span><span class="p">[</span><span class="n">b</span><span class="p">][</span><span class="n">c</span><span class="p">][</span><span class="n">u</span><span class="o">+</span><span class="n">T</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">out</span><span class="p">[</span><span class="n">b</span><span class="p">][</span><span class="n">c</span><span class="p">][</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span>
    <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</section>
<section id="implement-a-depthwise-convolution-operator-with-pytorch">
<h3>Implement a depthwise convolution operator with PyTorch<a class="headerlink" href="#implement-a-depthwise-convolution-operator-with-pytorch" title="Link to this heading">#</a></h3>
<p>It is very challenging to translate the Python reference code above to this code line. To come up with this, you have to know very well the underlying logic of these PyTorch operators.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">out</span> <span class="o">=</span> <span class="n">eps</span> <span class="o">+</span> <span class="n">F</span><span class="o">.</span><span class="n">conv1d</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ZeroPad2d</span><span class="p">((</span><span class="n">T</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))(</span><span class="n">k</span><span class="p">),</span> <span class="n">w</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">groups</span><span class="o">=</span><span class="n">C</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="implement-a-depthwise-convolution-operator-with-cuda">
<h3>Implement a depthwise convolution operator with CUDA<a class="headerlink" href="#implement-a-depthwise-convolution-operator-with-cuda" title="Link to this heading">#</a></h3>
<p>The CUDA reference code has much poorer readability: The outmost loop is implicitly defined by thread parallelism. The index calculation is complicated, and each element’s position in the matrix is not clear at a glance. Besides, it could be rather error-prone to implement more sophisticated algorithms with CUDA.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">kernel_forward</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">w</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">x</span><span class="p">,</span>
<span class="w">                               </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">eps</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">T</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">eps</span><span class="p">;</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">www</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">C</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">T</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">T</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t</span><span class="p">;</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">kk</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">T</span><span class="p">;</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">u</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">u</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">t</span><span class="p">;</span><span class="w"> </span><span class="n">u</span><span class="o">++</span><span class="p">){</span>
<span class="w">        </span><span class="n">s</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">www</span><span class="p">[</span><span class="n">u</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">kk</span><span class="p">[</span><span class="n">u</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">T</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">t</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Further, you need a proper compile environment to run your CUDA code! If you have precompiled your CUDA code into a dynamic link library, then you also need to spend time working hard on trivial matters such as environment settings and Python API encapsulation.</p>
</section>
<section id="implement-a-depthwise-convolution-operator-with-taichi">
<h3>Implement a depthwise convolution operator with Taichi<a class="headerlink" href="#implement-a-depthwise-convolution-operator-with-taichi" title="Link to this heading">#</a></h3>
<p>The Taichi reference code is almost identical to its Python counterpart. And a good advantage that Taichi has over CUDA is that, without worrying about low-level details like parallelization and pointer offsets, one can easily use Taichi to achieve comparable performance.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">taichi_forward_v0</span><span class="p">(</span>
        <span class="n">out</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">ndarray</span><span class="p">(</span><span class="n">ndim</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
        <span class="n">w</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">ndarray</span><span class="p">(</span><span class="n">ndim</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
        <span class="n">k</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">ndarray</span><span class="p">(</span><span class="n">ndim</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
        <span class="n">eps</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">):</span>

    <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">out</span><span class="p">:</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">t</span><span class="o">-</span><span class="n">T</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">s</span> <span class="o">+=</span> <span class="n">w</span><span class="p">[</span><span class="n">c</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="n">T</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">-</span><span class="p">(</span><span class="n">t</span><span class="o">-</span><span class="n">u</span><span class="p">)]</span> <span class="o">*</span> <span class="n">k</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">u</span><span class="o">+</span><span class="n">T</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">out</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span>
</pre></div>
</div>
</section>
<section id="id3">
<h3>Performance comparison<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<p>The following diagram shows that Taichi always shows a performance that is comparable to its CUDA counterpart or even better under certain circumstances.</p>
<p><img alt="comparison" src="https://user-images.githubusercontent.com/93570324/191012778-99408533-c3a2-4868-a750-e853a63d2697.png" /></p>
<blockquote>
<div><ul class="simple">
<li><p>The RWKV compute time in the diagram is in milliseconds. The less the compute time, the better the performance is.</p></li>
<li><p>‘Baseline’: The reference code is a faithful implementation of the algorithm without any modification.</p></li>
<li><p>v1 to v3: The three different optimized implementations.</p></li>
</ul>
</div></blockquote>
</section>
</section>
<section id="recap">
<h2>Recap<a class="headerlink" href="#recap" title="Link to this heading">#</a></h2>
<p>PyTorch is efficient in handling a large proportion of computation tasks in machine learning. Still, there are niches and needs that it falls short of addressing, such as native support for many operators and unsatisfactory runtime performance.</p>
<p>As a high-performance programming language embedded in Python, Taichi features:</p>
<ul class="simple">
<li><p>Easy readability,</p></li>
<li><p>Optimized memory consumption,</p></li>
<li><p>Runtime performance comparable to that of CUDA,</p></li>
<li><p>Good portability that encourages reproducible code sharing among the community.</p></li>
</ul>
<p>All these features set Taichi apart as a convenient tool for ML operator customization.The two examples provided in this document give you a glimpse of how Taichi and PyTorch can complement each other to solve real-world high-performance programming issues.</p>
</section>
<section id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Link to this heading">#</a></h2>
<p><a href="#id10"><span class="problematic" id="id4">[^1]</span></a> <a class="reference external" href="https://github.com/ailzhang/blog_code/blob/master/tile/demo_torch.py">Pure PyTorch padding</a>
<a href="#id11"><span class="problematic" id="id5">[^2]</span></a> <a class="reference external" href="https://github.com/ailzhang/blog_code/blob/master/tile/demo_taichi.py">Padding PyTorch tensor in Taichi kernel</a>
<a href="#id12"><span class="problematic" id="id6">[^3]</span></a> <a class="reference external" href="https://github.com/BlinkDL/RWKV-CUDA/tree/main/depthwise_conv1d">RWKV-CUDA</a>
<a href="#id13"><span class="problematic" id="id7">[^4]</span></a> <a class="reference external" href="https://github.com/ailzhang/blog_code/tree/master/rwkv">RWKV-Taichi </a></p>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="accelerate_python.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Accelerate Python with Taichi</p>
      </div>
    </a>
    <a class="right-next"
       href="../basic/field.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Fields</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preprocessing">Data preprocessing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#padding-with-pytorch">Padding with PyTorch</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#padding-with-taichi">Padding with Taichi</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-comparison">Performance comparison</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#customize-ml-operators">Customize ML operators</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implement-a-depthwise-convolution-operator-with-python">Implement a depthwise convolution operator with Python</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implement-a-depthwise-convolution-operator-with-pytorch">Implement a depthwise convolution operator with PyTorch</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implement-a-depthwise-convolution-operator-with-cuda">Implement a depthwise convolution operator with CUDA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implement-a-depthwise-convolution-operator-with-taichi">Implement a depthwise convolution operator with Taichi</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Performance comparison</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recap">Recap</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reference">Reference</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/user_guide/get-started/accelerate_pytorch.md.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2023 Taichi Graphics Inc; 2025 Genesis AI Inc.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>