
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Differentiable Programming &#8212; Taichi 1.8.0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=b51e6972"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'user_guide/differentiable/differentiable_programming';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Type System" href="../type_system/type.html" />
    <link rel="prev" title="Use quantized data types" href="../advanced/quant.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="1.8.0" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Taichi 1.8.0 documentation</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    User guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../autoapi/index.html">
    API Reference
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    User guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../autoapi/index.html">
    API Reference
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../get-started/hello_world.html">Hello, World!</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get-started/accelerate_python.html">Accelerate Python with Taichi</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get-started/accelerate_pytorch.html">Accelerate PyTorch with Taichi</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Basic</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../basic/field.html">Fields</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/ndarray.html">Taichi Ndarray</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/layout.html">Fields (advanced)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/offset.html">Coordinate Offsets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/external.html">Interacting with External Arrays</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/sparse.html">Spatially Sparse Data Structures</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Kernels</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../kernels/kernel_function.html">Kernels and Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../kernels/kernel_sync.html">Synchronization between Kernels and Python Scope</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Math</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../math/linear_solver.html">Linear Solver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../math/math_module.html">Math Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../math/sparse_matrix.html">Sparse Matrix</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Performance Tuning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../performance_tuning/performance.html">Performance Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance_tuning/profiler.html">Profiler</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../advanced/data_oriented_class.html">Data-Oriented Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dataclass.html">Taichi Dataclass</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/meta.html">Metaprogramming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/quant.html">Use quantized data types</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Differentiable</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Differentiable Programming</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Type System</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../type_system/type.html">Type System</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../reference/global_settings.html">Global Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/language_reference.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/operator.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/simt.html">SIMT Intrinsics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/syntax_sugars.html">Syntax Sugars</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Internals</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../internals/compilation.html">Life of a Taichi Kernel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../internals/internal.html">Internal Designs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">glossary</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../glossary/glossary.html">Glossary</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">FAQs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../faqs/faq.html">Frequently Asked Questions</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">User guide</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Differentiable Programming</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="differentiable-programming">
<h1>Differentiable Programming<a class="headerlink" href="#differentiable-programming" title="Link to this heading">#</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>Differentiable programming proves to be useful in a wide variety of areas
such as scientific computing and artificial intelligence. For instance,
a controller optimization system equipped with differentiable simulators converges one to
four orders of magnitude faster than those using model-free reinforcement learning algorithms.<a class="footnote-reference brackets" href="#id3" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a><a class="footnote-reference brackets" href="#id4" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a></p>
<p>Suppose you have the following kernel:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="p">())</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="p">())</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_y</span><span class="p">():</span>
    <span class="n">y</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="kc">None</span><span class="p">])</span>
</pre></div>
</div>
<p>Now if you want to get the derivative of <code class="docutils literal notranslate"><span class="pre">y</span></code> with respect to <code class="docutils literal notranslate"><span class="pre">x</span></code>:
<code class="docutils literal notranslate"><span class="pre">dy/dx</span></code>, it is straightforward to write out the gradient kernel manually:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">())</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">())</span>
<span class="n">dy_dx</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">())</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_dy_dx</span><span class="p">():</span>
    <span class="n">dy_dx</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="kc">None</span><span class="p">])</span>
</pre></div>
</div>
<p>However, as you make a change to <code class="docutils literal notranslate"><span class="pre">compute_y</span></code>, you have to rework the gradient formula
by hand and update <code class="docutils literal notranslate"><span class="pre">compute_dy_dx</span></code> accordingly. Apparently, when
the kernel becomes larger and gets frequently updated, this manual workflow is
really error-prone and hard to maintain.</p>
<p>If you run into this situation, Taichi’s handy automatic differentiation (autodiff)
system comes to your rescue! Taichi supports gradient evaluation through
either <code class="docutils literal notranslate"><span class="pre">ti.ad.Tape()</span></code> or the more flexible <code class="docutils literal notranslate"><span class="pre">kernel.grad()</span></code> syntax.</p>
</section>
<section id="using-ti-ad-tape">
<h2>Using <code class="docutils literal notranslate"><span class="pre">ti.ad.Tape()</span></code><a class="headerlink" href="#using-ti-ad-tape" title="Link to this heading">#</a></h2>
<p>Let’s still take the <code class="docutils literal notranslate"><span class="pre">compute_y</span></code> kernel above for an explanation.
Using <code class="docutils literal notranslate"><span class="pre">ti.ad.Tape()</span></code> is the easiest way to obtain a kernel that computes <code class="docutils literal notranslate"><span class="pre">dy/dx</span></code>:</p>
<ol class="arabic simple">
<li><p>Enable <code class="docutils literal notranslate"><span class="pre">needs_grad=True</span></code> option when declaring fields involved in
the derivative chain.</p></li>
<li><p>Use context manager <code class="docutils literal notranslate"><span class="pre">with</span> <span class="pre">ti.ad.Tape(y):</span></code> to capture the kernel invocations which you want to automatically differentiate.</p></li>
<li><p>Now <code class="docutils literal notranslate"><span class="pre">dy/dx</span></code> value at current <code class="docutils literal notranslate"><span class="pre">x</span></code> is available at <code class="docutils literal notranslate"><span class="pre">x.grad[None]</span></code>.</p></li>
</ol>
<p>The following code snippet explains the steps above:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">needs_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">needs_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_y</span><span class="p">():</span>
    <span class="n">y</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="kc">None</span><span class="p">])</span>

<span class="k">with</span> <span class="n">ti</span><span class="o">.</span><span class="n">ad</span><span class="o">.</span><span class="n">Tape</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
    <span class="n">compute_y</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dy/dx =&#39;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="s1">&#39; at x =&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="kc">None</span><span class="p">])</span>
</pre></div>
</div>
<section id="case-study-gravity-simulation">
<h3>Case study: gravity simulation<a class="headerlink" href="#case-study-gravity-simulation" title="Link to this heading">#</a></h3>
<p>A common problem in physical simulation is that it is usually easy to compute
energy but hard to compute force on every particle,
for example <a class="reference external" href="https://github.com/victoriacity/taichimd/blob/5a44841cc8dfe5eb97de51f1d46f1bede1cc9936/taichimd/interaction.py#L190-L220">Bond bending (and torsion) in molecular dynamics</a>
and <a class="reference external" href="https://github.com/taichi-dev/taichi/blob/master/python/taichi/examples/simulation/fem128.py">FEM with hyperelastic energy functions</a>.
Recall that we can differentiate
(negative) potential energy to get forces: <code class="docutils literal notranslate"><span class="pre">F_i</span> <span class="pre">=</span> <span class="pre">-dU</span> <span class="pre">/</span> <span class="pre">dx_i</span></code>. So once you have coded
a kernel that computes the potential energy, you may use Taichi’s autodiff
system to obtain the derivatives and then <code class="docutils literal notranslate"><span class="pre">F_i</span></code> on each particle.</p>
<p>Taking
<a class="reference external" href="https://github.com/taichi-dev/taichi/blob/master/python/taichi/examples/simulation/ad_gravity.py">examples/simulation/ad_gravity.py</a>
as an example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">taichi</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ti</span>
<span class="n">ti</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">dt</span> <span class="o">=</span> <span class="mf">1e-5</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">Vector</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">needs_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># particle positions</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">Vector</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>  <span class="c1"># particle velocities</span>
<span class="n">U</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">needs_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># potential energy</span>


<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_U</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">ti</span><span class="o">.</span><span class="n">ndrange</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="c1"># r.norm(1e-3) is equivalent to ti.sqrt(r.norm()**2 + 1e-3)</span>
        <span class="c1"># This is to prevent 1/0 error which can cause wrong derivative</span>
        <span class="n">U</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">/</span> <span class="n">r</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">)</span>  <span class="c1"># U += -1 / |r|</span>


<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">advance</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
        <span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dt</span> <span class="o">*</span> <span class="o">-</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>  <span class="c1"># dv/dt = -dU/dx</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
        <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>  <span class="c1"># dx/dt = v</span>


<span class="k">def</span><span class="w"> </span><span class="nf">substep</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">ti</span><span class="o">.</span><span class="n">ad</span><span class="o">.</span><span class="n">Tape</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">U</span><span class="p">):</span>
        <span class="c1"># Kernel invocations in this scope will later contribute to partial derivatives of</span>
        <span class="c1"># U with respect to input variables such as x.</span>
        <span class="n">compute_U</span><span class="p">(</span>
        <span class="p">)</span>  <span class="c1"># The tape will automatically compute dU/dx and save the results in x.grad</span>
    <span class="n">advance</span><span class="p">()</span>


<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">init</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
        <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">ti</span><span class="o">.</span><span class="n">random</span><span class="p">(),</span> <span class="n">ti</span><span class="o">.</span><span class="n">random</span><span class="p">()]</span>


<span class="n">init</span><span class="p">()</span>
</pre></div>
</div>
<div class="note docutils">
<p>The argument <code class="docutils literal notranslate"><span class="pre">U</span></code> to <code class="docutils literal notranslate"><span class="pre">ti.ad.Tape(U)</span></code> must be a 0D field.</p>
<p>To use autodiff with multiple output variables, see the
<code class="docutils literal notranslate"><span class="pre">kernel.grad()</span></code> usage below.</p>
</div>
<div class="note docutils">
<p><code class="docutils literal notranslate"><span class="pre">ti.ad.Tape(U)</span></code> automatically sets <em><code class="docutils literal notranslate"><span class="pre">U[None]</span></code></em> to <code class="docutils literal notranslate"><span class="pre">0</span></code> on
start up.</p>
</div>
<div class="tip docutils">
<p>See
<a class="reference external" href="https://github.com/taichi-dev/taichi/blob/master/python/taichi/examples/simulation/mpm_lagrangian_forces.py">examples/simulation/mpm_lagrangian_forces.py</a>
and
<a class="reference external" href="https://github.com/taichi-dev/taichi/blob/master/python/taichi/examples/simulation/fem99.py">examples/simulation/fem99.py</a>
for examples on using autodiff-based force evaluation MPM and FEM.</p>
</div>
</section>
</section>
<section id="using-kernel-grad">
<h2>Using <code class="docutils literal notranslate"><span class="pre">kernel.grad()</span></code><a class="headerlink" href="#using-kernel-grad" title="Link to this heading">#</a></h2>
<p>As mentioned above, <code class="docutils literal notranslate"><span class="pre">ti.ad.Tape()</span></code> can only track a 0D field as the output variable.
If there are multiple output variables that you want to back-propagate
gradients to inputs, call <code class="docutils literal notranslate"><span class="pre">kernel.grad()</span></code> instead of <code class="docutils literal notranslate"><span class="pre">ti.ad.Tape()</span></code>.
Different from using <code class="docutils literal notranslate"><span class="pre">ti.ad.Tape()</span></code>, you need to set the <code class="docutils literal notranslate"><span class="pre">grad</span></code> of the output variables themselves to <code class="docutils literal notranslate"><span class="pre">1</span></code> manually
before calling <code class="docutils literal notranslate"><span class="pre">kernel.grad()</span></code>. The reason is that the <code class="docutils literal notranslate"><span class="pre">grad</span></code> of the output variables themselves
will always be multiplied to the <code class="docutils literal notranslate"><span class="pre">grad</span></code> with respect to the inputs at the end of the back-propagation.
By calling <code class="docutils literal notranslate"><span class="pre">ti.ad.Tape()</span></code>, you have the program do this under the hood.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">taichi</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ti</span>
<span class="n">ti</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">16</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">needs_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">needs_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">loss2</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">needs_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">func</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
       <span class="n">loss</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">+=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span>
       <span class="n">loss2</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">+=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>

<span class="c1"># Set the `grad` of the output variables to `1` before calling `func.grad()`.</span>
<span class="n">loss</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">loss2</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">func</span><span class="p">()</span>
<span class="n">func</span><span class="o">.</span><span class="n">grad</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span>
</pre></div>
</div>
<div class="tip docutils">
<p>It may be tedius to write out <code class="docutils literal notranslate"><span class="pre">need_grad=True</span></code> for every input in a complicated use case.
Alternatively, Taichi provides an API <code class="docutils literal notranslate"><span class="pre">ti.root.lazy_grad()</span></code> that automatically places the
gradient fields following the layout of their primal fields.</p>
</div>
<div class="caution docutils">
<p>When using <code class="docutils literal notranslate"><span class="pre">kernel.grad()</span></code>, it is recommended that you always run forward kernel before backward, for example <code class="docutils literal notranslate"><span class="pre">kernel();</span> <span class="pre">kernel.grad()</span></code>. If global fields used in the derivative calculation get mutated in the forward run, skipping
<code class="docutils literal notranslate"><span class="pre">kernel()</span></code> breaks global data access rule #1 below and may produce incorrect gradients.</p>
</div>
</section>
<section id="limitations-of-taichi-autodiff-system">
<h2>Limitations of Taichi autodiff system<a class="headerlink" href="#limitations-of-taichi-autodiff-system" title="Link to this heading">#</a></h2>
<p>Unlike tools such as TensorFlow where <strong>immutable</strong> output buffers are
generated, the <strong>imperative</strong> programming paradigm adopted by Taichi
allows programmers to freely modify global fields.</p>
<p>To make automatic differentiation well-defined under this setting, the following
rules are enforced when writing differentiable programs in Taichi:</p>
<section id="global-data-access-rules">
<h3>Global Data Access Rules<a class="headerlink" href="#global-data-access-rules" title="Link to this heading">#</a></h3>
<p>Currently Taichi’s autodiff implementation does not save intermediate results of global fields which might be used in the backward pass. Therefore mutation is forbidden once you’ve read from a global field.</p>
<div class="note docutils">
<p>Once you read an element in a field, the element cannot be mutated anymore.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">taichi</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ti</span>
<span class="n">ti</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">16</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">needs_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">needs_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">needs_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">func_broke_rule_1</span><span class="p">():</span>
    <span class="c1"># BAD: broke global data access rule #1, reading global field and before mutation is done.</span>
    <span class="n">loss</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">b</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span>
    <span class="n">b</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">100</span>


<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">func_equivalent</span><span class="p">():</span>
    <span class="n">loss</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
<span class="n">b</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">loss</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">with</span> <span class="n">ti</span><span class="o">.</span><span class="n">ad</span><span class="o">.</span><span class="n">Tape</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
    <span class="n">func_broke_rule_1</span><span class="p">()</span>
<span class="c1"># Call func_equivalent to see the correct result</span>
<span class="c1"># with ti.ad.Tape(loss):</span>
    <span class="c1"># func_equivalent()</span>

<span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mf">10.0</span>
</pre></div>
</div>
<div class="note docutils">
<p>If a global field element is written more than once, then starting from the second write, the write <strong>must</strong> come in the form of an atomic add (“accumulation”, using <code class="docutils literal notranslate"><span class="pre">ti.atomic_add</span></code> or simply <code class="docutils literal notranslate"><span class="pre">+=</span></code>). Although <code class="docutils literal notranslate"><span class="pre">+=</span></code> violates rule #1 above since it reads the old value before computing the sum, it is the only special case of “read before mutation” that Taichi allows in the autodiff system.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">taichi</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ti</span>
<span class="n">ti</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">16</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">needs_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">needs_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">func_break_rule_2</span><span class="p">():</span>
    <span class="n">loss</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">+=</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="c1"># Bad: broke global data access rule #2, it&#39;s not an atomic_add.</span>
    <span class="n">loss</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*=</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">func_equivalent</span><span class="p">():</span>
    <span class="n">loss</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
<span class="n">loss</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">loss</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">func_break_rule_2</span><span class="p">()</span>
<span class="n">func_break_rule_2</span><span class="o">.</span><span class="n">grad</span><span class="p">()</span>
<span class="c1"># Call func_equivalent to see the correct result</span>
<span class="c1"># func_equivalent()</span>
<span class="c1"># func_equivalent.grad()</span>
<span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mf">4.0</span>
<span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="mf">3.0</span>
</pre></div>
</div>
</section>
<section id="global-data-access-rule-violation-checker">
<h3>Global data access rule violation checker<a class="headerlink" href="#global-data-access-rule-violation-checker" title="Link to this heading">#</a></h3>
<p>A checker is provided for detecting potential violations of global data access rules.</p>
<ol class="arabic simple">
<li><p>The checker only works in debug mode. To enable it, set <code class="docutils literal notranslate"><span class="pre">debug=True</span></code> when calling <code class="docutils literal notranslate"><span class="pre">ti.init()</span></code>.</p></li>
<li><p>Set <code class="docutils literal notranslate"><span class="pre">validation=True</span></code> when using <code class="docutils literal notranslate"><span class="pre">ti.ad.Tape()</span></code> to validate the kernels captured by <code class="docutils literal notranslate"><span class="pre">ti.ad.Tape()</span></code>.
<em>The checker pinpoints the line of code breaking the rules, if a violation occurs.</em></p></li>
</ol>
<p>For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">taichi</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ti</span>
<span class="n">ti</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">debug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">needs_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">needs_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">needs_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">func_1</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">loss</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">+=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">b</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">func_2</span><span class="p">():</span>
    <span class="n">b</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">100</span>

<span class="n">b</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="k">with</span> <span class="n">ti</span><span class="o">.</span><span class="n">ad</span><span class="o">.</span><span class="n">Tape</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">validation</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">func_1</span><span class="p">()</span>
    <span class="n">func_2</span><span class="p">()</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">taichi.lang.exception.TaichiAssertionError:</span>
<span class="sd">(kernel=func_2_c78_0) Breaks the global data access rule. Snode S10 is overwritten unexpectedly.</span>
<span class="sd">File &quot;across_kernel.py&quot;, line 16, in func_2:</span>
<span class="sd">    b[None] += 100</span>
<span class="sd">    ^^^^^^^^^^^^^^</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</section>
<section id="avoid-mixed-usage-of-parallel-for-loop-and-non-for-statements">
<h3>Avoid mixed usage of parallel for-loop and non-for statements<a class="headerlink" href="#avoid-mixed-usage-of-parallel-for-loop-and-non-for-statements" title="Link to this heading">#</a></h3>
<p>Mixed usage of parallel for-loops and non-for statements are not supported in the autodiff system.
Please split the two kinds of statements into different kernels.</p>
<div class="note docutils">
<p>Kernel body must only consist of either multiple for-loops or non-for statements.</p>
</div>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">differentiable_task</span><span class="p">():</span>
    <span class="c1"># Bad: mixed usage of a parallel for-loop and a statement without looping. Please split them into two kernels.</span>
    <span class="n">loss</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">+=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>Violation of this rule results in an error.</p>
<div class="danger docutils">
<p>Violation of rules above might result in incorrect gradient result without a proper error.
We’re actively working on improving the error reporting mechanism for it. Please feel free
to open a <a class="reference external" href="https://github.com/taichi-dev/taichi/issues/new?assignees=&amp;amp;labels=potential+bug&amp;amp;template=bug_report.md&amp;amp;title=">github issue</a>
if you see any silent wrong results.</p>
</div>
</section>
<section id="write-differentiable-code-inside-a-taichi-kernel">
<h3>Write differentiable code inside a Taichi kernel<a class="headerlink" href="#write-differentiable-code-inside-a-taichi-kernel" title="Link to this heading">#</a></h3>
<p>Taichi’s compiler only captures the code in the Taichi scope when performing the source code transformation for autodiff. Therefore, only the code written in Taichi scope is auto-differentiated. Although you can modify the <code class="docutils literal notranslate"><span class="pre">grad</span></code> of a field in python scope manually, the code is not auto-differentiated.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">taichi</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ti</span>

<span class="n">ti</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">needs_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">needs_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">differentiable_task</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">loss</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">+=</span> <span class="n">ti</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="kc">None</span><span class="p">])</span> <span class="o">+</span> <span class="mf">1.0</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">manipulation_in_kernel</span><span class="p">():</span>
    <span class="n">loss</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">+=</span> <span class="n">ti</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="kc">None</span><span class="p">])</span> <span class="o">+</span> <span class="mf">1.0</span>


<span class="n">x</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="k">with</span> <span class="n">ti</span><span class="o">.</span><span class="n">ad</span><span class="o">.</span><span class="n">Tape</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">):</span>
    <span class="c1"># The line below in python scope only contribute to the forward pass</span>
    <span class="c1"># but not the backward pass i.e., not auto-differentiated.</span>
    <span class="n">loss</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">+=</span> <span class="n">ti</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="kc">None</span><span class="p">])</span> <span class="o">+</span> <span class="mf">1.0</span>

    <span class="c1"># Code in Taichi scope i.e. inside Taichi kernels, is auto-differentiated.</span>
    <span class="n">manipulation_in_kernel</span><span class="p">()</span>
    <span class="n">differentiable_task</span><span class="p">()</span>

<span class="c1"># The outputs are 5.0 and 4.0</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="kc">None</span><span class="p">])</span>

<span class="c1"># You can modify the grad of a field manually in python scope, e.g., clear the grad.</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="c1"># The output is 0.0</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="kc">None</span><span class="p">])</span>
</pre></div>
</div>
</section>
</section>
<section id="extending-taichi-autodiff-system">
<h2>Extending Taichi Autodiff system<a class="headerlink" href="#extending-taichi-autodiff-system" title="Link to this heading">#</a></h2>
<p>Sometimes user may want to override the gradients provided by the Taichi autodiff system. For example, when differentiating a 3D singular value decomposition (SVD) used in an iterative
solver, it is preferred to use a manually engineered SVD derivative subroutine for better numerical stability.
Taichi provides two decorators <code class="docutils literal notranslate"><span class="pre">ti.ad.grad_replaced</span></code> and <code class="docutils literal notranslate"><span class="pre">ti.ad.grad_for</span></code> to overwrite the default
automatic differentiation behavior.</p>
<p>The following is a simple example to use customized gradient function in autodiff:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">taichi</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ti</span>
<span class="n">ti</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">)</span>
<span class="n">total</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">ti</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">ti</span><span class="o">.</span><span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">place</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">ti</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">place</span><span class="p">(</span><span class="n">total</span><span class="p">)</span>
<span class="n">ti</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">lazy_grad</span><span class="p">()</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">func</span><span class="p">(</span><span class="n">mul</span><span class="p">:</span> <span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">ti</span><span class="o">.</span><span class="n">atomic_add</span><span class="p">(</span><span class="n">total</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">mul</span><span class="p">)</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">ad</span><span class="o">.</span><span class="n">grad_replaced</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="n">mul</span><span class="p">):</span>
    <span class="n">func</span><span class="p">(</span><span class="n">mul</span><span class="p">)</span>
    <span class="n">func</span><span class="p">(</span><span class="n">mul</span><span class="p">)</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">ad</span><span class="o">.</span><span class="n">grad_for</span><span class="p">(</span><span class="n">forward</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">backward</span><span class="p">(</span><span class="n">mul</span><span class="p">):</span>
    <span class="n">func</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">mul</span><span class="p">)</span>

<span class="k">with</span> <span class="n">ti</span><span class="o">.</span><span class="n">ad</span><span class="o">.</span><span class="n">Tape</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">total</span><span class="p">):</span>
    <span class="n">forward</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span>
</pre></div>
</div>
<p>Customized gradient function works with both <code class="docutils literal notranslate"><span class="pre">ti.ad.Tape()</span></code> and <code class="docutils literal notranslate"><span class="pre">kernel.grad()</span></code>. More examples can be found at <code class="docutils literal notranslate"><span class="pre">test_customized_grad.py</span></code>.</p>
<section id="checkpointing">
<h3>Checkpointing<a class="headerlink" href="#checkpointing" title="Link to this heading">#</a></h3>
<p>Another use case of customized gradient function is checkpointing. We can use recomputation to save memory space through
a user-defined gradient function.
<a class="reference external" href="https://github.com/yuanming-hu/difftaichi/blob/master/examples/diffmpm.py#L226-L244">diffmpm.py</a>
demonstrates that by defining a customized gradient function that recomputes the grid states during backward,
we can reuse the grid states and allocate only one copy compared to <code class="docutils literal notranslate"><span class="pre">O(n)</span></code> copies in a native implementation
without customized gradient function.</p>
</section>
</section>
<section id="difftaichi">
<h2>DiffTaichi<a class="headerlink" href="#difftaichi" title="Link to this heading">#</a></h2>
<p>The <a class="reference external" href="https://github.com/yuanming-hu/difftaichi">DiffTaichi repo</a>
contains 10 differentiable physical simulators built with Taichi
differentiable programming. A few examples with neural network
controllers optimized using differentiable simulators and brute-force
gradient descent:</p>
<p><img alt="image" src="https://github.com/yuanming-hu/public_files/raw/master/learning/difftaichi/ms3_final-cropped.gif" /></p>
<p><img alt="image" src="https://github.com/yuanming-hu/public_files/raw/master/learning/difftaichi/rb_final2.gif" /></p>
<p><img alt="image" src="https://github.com/yuanming-hu/public_files/raw/master/learning/difftaichi/diffmpm3d.gif" /></p>
<div class="tip docutils">
<p>Check out <a class="reference external" href="https://arxiv.org/pdf/1910.00935.pdf">the DiffTaichi paper</a>
and <a class="reference external" href="https://www.youtube.com/watch?v=Z1xvAZve9aE">video</a> to learn more
about Taichi differentiable programming.</p>
</div>
</section>
<section id="forward-mode-autodiff">
<h2>Forward-Mode Autodiff<a class="headerlink" href="#forward-mode-autodiff" title="Link to this heading">#</a></h2>
<p>Automatic differentiation (Autodiff) has two modes, reverse mode and forward mode.</p>
<ul class="simple">
<li><p>Reverse mode computes Vector-Jacobian Product (VJP), which means computing one <em>row</em> of the Jacobian matrix at a time. Therefore, reverse mode is more efficient for functions, which have more inputs than outputs. <code class="docutils literal notranslate"><span class="pre">ti.ad.Tape()</span></code> and <code class="docutils literal notranslate"><span class="pre">kernel.grad()</span></code> are for reverse-mode autodiff.</p></li>
<li><p>Forward mode computes Jacobian-Vector Product (JVP), which means computing one <em>column</em> of the Jacobian matrix at a time. Therefore, forward mode is more efficient for functions, which have more outputs than inputs. As of v1.1.0, Taichi supports forward-mode autodiff. <code class="docutils literal notranslate"><span class="pre">ti.ad.FwdMode()</span></code> and <code class="docutils literal notranslate"><span class="pre">ti.root.lazy_dual()</span></code> are for forward-mode autodiff.</p></li>
</ul>
<section id="using-ti-ad-fwdmode">
<h3>Using <code class="docutils literal notranslate"><span class="pre">ti.ad.FwdMode()</span></code><a class="headerlink" href="#using-ti-ad-fwdmode" title="Link to this heading">#</a></h3>
<p>The usage of <code class="docutils literal notranslate"><span class="pre">ti.ad.FwdMode()</span></code> is similar to that of <code class="docutils literal notranslate"><span class="pre">ti.ad.Tape()</span></code>. Here we reuse the example for reverse mode above for <code class="docutils literal notranslate"><span class="pre">ti.ad.FwdMode()</span></code>.</p>
<ol class="arabic">
<li><p>Set <code class="docutils literal notranslate"><span class="pre">needs_dual=True</span></code> when declaring fields involved in a derivative chain.</p>
<blockquote>
<div><p>The <code class="docutils literal notranslate"><span class="pre">dual</span></code> here indicates <code class="docutils literal notranslate"><span class="pre">dual</span> <span class="pre">number</span></code> in math. This is because forward-mode autodiff is equivalent to evaluating a function with dual numbers.</p>
</div></blockquote>
</li>
<li><p>Use context manager with <code class="docutils literal notranslate"><span class="pre">ti.ad.FwdMode(loss=y,</span> <span class="pre">param=x)</span></code> to capture the kernel invocations to automatically differentiate.</p>
<p><em>Now dy/dx value at the current x is available at function output <code class="docutils literal notranslate"><span class="pre">y.dual[None]</span></code>.</em></p>
</li>
</ol>
<p>The following code snippet explains the steps above:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">taichi</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ti</span>
<span class="n">ti</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">needs_dual</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">needs_dual</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_y</span><span class="p">():</span>
    <span class="n">y</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="kc">None</span><span class="p">])</span>

<span class="c1"># `loss`: The function&#39;s output</span>
<span class="c1"># `param`: The input of the function</span>
<span class="k">with</span> <span class="n">ti</span><span class="o">.</span><span class="n">ad</span><span class="o">.</span><span class="n">FwdMode</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">param</span><span class="o">=</span><span class="n">x</span><span class="p">):</span>
    <span class="n">compute_y</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dy/dx =&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">dual</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="s1">&#39; at x =&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="kc">None</span><span class="p">])</span>
</pre></div>
</div>
<div class="note docutils">
<p><code class="docutils literal notranslate"><span class="pre">ti.ad.FwdMode()</span></code> automatically clears the dual field of <code class="docutils literal notranslate"><span class="pre">loss</span></code>.</p>
</div>
<p><code class="docutils literal notranslate"><span class="pre">ti.ad.FwdMode()</span></code> supports multiple inputs and outputs:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">param</span></code> can be an N-D field.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">loss</span></code> can be an individual N-D field or a list of N-D fields.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">seed</span></code> is the ‘vector’ in Jacobian-vector product, which controls the parameter that is computed derivative with respect to. <code class="docutils literal notranslate"><span class="pre">seed</span></code> is required if <code class="docutils literal notranslate"><span class="pre">param</span></code> is not a scalar field.</p></li>
</ul>
<p>The following code snippet shows another two cases with multiple inputs and outputs: With <code class="docutils literal notranslate"><span class="pre">seed=[1.0,</span> <span class="pre">0.0]</span> </code>or <code class="docutils literal notranslate"><span class="pre">seed=[0.0,</span> <span class="pre">1.0]</span></code> , we can compute derivatives solely with respect to <code class="docutils literal notranslate"><span class="pre">x_0</span></code> or <code class="docutils literal notranslate"><span class="pre">x_1</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">taichi</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ti</span>
<span class="n">ti</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">N_param</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">N_loss</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">N_param</span><span class="p">,</span> <span class="n">needs_dual</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">ti</span><span class="o">.</span><span class="n">f32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">N_loss</span><span class="p">,</span> <span class="n">needs_dual</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nd">@ti</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_y</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_loss</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_param</span><span class="p">):</span>
            <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">ti</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>

<span class="c1"># Compute derivatives with respect to x_0</span>
<span class="c1"># `seed` is required if `param` is not a scalar field</span>
<span class="k">with</span> <span class="n">ti</span><span class="o">.</span><span class="n">ad</span><span class="o">.</span><span class="n">FwdMode</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">param</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]):</span>
    <span class="n">compute_y</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dy/dx_0 =&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">dual</span><span class="p">,</span> <span class="s1">&#39; at x_0 =&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># Compute derivatives with respect to x_1</span>
<span class="c1"># `seed` is required if `param` is not a scalar field</span>
<span class="k">with</span> <span class="n">ti</span><span class="o">.</span><span class="n">ad</span><span class="o">.</span><span class="n">FwdMode</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">param</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]):</span>
    <span class="n">compute_y</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dy/dx_1 =&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">dual</span><span class="p">,</span> <span class="s1">&#39; at x_1 =&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<div class="tip docutils">
<p>Just as reverse-mode autodiff, Taichi’s forward-mode autodiff provides <code class="docutils literal notranslate"><span class="pre">ti.root.lazy_dual()</span></code>, which automatically places the dual fields following the layout of their primal fields.</p>
</div>
</section>
</section>
</section>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id3" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://papers.nips.cc/paper/2018/file/842424a1d0595b76ec4fa03c46e8d755-Paper.pdf">End-to-End Differentiable Physics for Learning and Control
</a></p>
</aside>
<aside class="footnote brackets" id="id4" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://arxiv.org/pdf/1810.01054.pdf">ChainQueen: A Real-Time Differentiable Physical Simulator for Soft Robotics</a></p>
</aside>
</aside>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../advanced/quant.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Use quantized data types</p>
      </div>
    </a>
    <a class="right-next"
       href="../type_system/type.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Type System</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-ti-ad-tape">Using <code class="docutils literal notranslate"><span class="pre">ti.ad.Tape()</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#case-study-gravity-simulation">Case study: gravity simulation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-kernel-grad">Using <code class="docutils literal notranslate"><span class="pre">kernel.grad()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-of-taichi-autodiff-system">Limitations of Taichi autodiff system</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#global-data-access-rules">Global Data Access Rules</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#global-data-access-rule-violation-checker">Global data access rule violation checker</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#avoid-mixed-usage-of-parallel-for-loop-and-non-for-statements">Avoid mixed usage of parallel for-loop and non-for statements</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#write-differentiable-code-inside-a-taichi-kernel">Write differentiable code inside a Taichi kernel</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extending-taichi-autodiff-system">Extending Taichi Autodiff system</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#checkpointing">Checkpointing</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#difftaichi">DiffTaichi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forward-mode-autodiff">Forward-Mode Autodiff</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-ti-ad-fwdmode">Using <code class="docutils literal notranslate"><span class="pre">ti.ad.FwdMode()</span></code></a></li>
</ul>
</li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/user_guide/differentiable/differentiable_programming.md.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2023 Taichi Graphics Inc; 2025 Genesis AI Inc.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>